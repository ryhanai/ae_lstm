{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2773276/2747308035.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'../checkpoints/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  4.5881944,   4.3886976,   4.2572284, ...,   6.539229 ,\n",
       "          6.531567 ,   6.8968353],\n",
       "       [  4.9612384,   4.7239246,   4.695693 , ...,   6.9643345,\n",
       "          7.0257616,   7.3885427],\n",
       "       [  5.1125097,   5.1153655,   5.0791407, ...,   7.4590383,\n",
       "          7.3869867,   7.5924773],\n",
       "       ...,\n",
       "       [290.68063  , 291.04498  , 291.2563   , ..., 297.63953  ,\n",
       "        297.91287  , 298.27298  ],\n",
       "       [291.42126  , 291.7223   , 292.38165  , ..., 298.53845  ,\n",
       "        298.81622  , 298.81033  ],\n",
       "       [291.74466  , 292.03473  , 293.48035  , ..., 299.63245  ,\n",
       "        299.06766  , 300.2733   ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from depth_anything_v2.dpt import DepthAnythingV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "model_configs = {\n",
    "    'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
    "    'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
    "    'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
    "    'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
    "}\n",
    "\n",
    "encoder = 'vitl' # or 'vits', 'vitb', 'vitg'\n",
    "\n",
    "model = DepthAnythingV2(**model_configs[encoder])\n",
    "model.load_state_dict(torch.load(f'../checkpoints/depth_anything_v2_{encoder}.pth', map_location='cpu'))\n",
    "model = model.to(DEVICE).eval()\n",
    "\n",
    "scene = 3\n",
    "view = 0\n",
    "image_path = f'/home/ryo/Dataset/forcemap/tabletop_airec241008/rgb{scene:05d}_{view:05d}.jpg'\n",
    "raw_img = cv2.imread(image_path)\n",
    "depth = model.infer_image(raw_img) # HxW raw depth map in numpy\n",
    "\n",
    "depth\n",
    "# display(raw_img)\n",
    "# display(depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v5の実験\n",
    "・スケールは重要：vits -> vitbでかなり性能が上がった\n",
    "　・vitlならさらに性能が上がるか（必ずしもそうでない．良いseedを引いただけか？）\n",
    "・seedによる当たり外れが非常に大きいかも\n",
    "　・同じ条件で2.9e-02くらいから中々下がらないケースもある\n",
    "\n",
    "・architectureの検討項目\n",
    "　・入力画像のNormalization：pre-trainingの分布に合わせる（1回のtrialでは悪くなった．seedの問題の方が大きそう）\n",
    "　・outputのactivation：relu vs sigmoid（dataのrangeを考えるとsigmoidの方が良さそうだが，1回のtrialではreluが良かった）\n",
    "　　・これは複数回試しても明らかにreluの方が良い\n",
    "　・batch size：8が良さそう\n",
    "　・学習率：5e-4が良さそう\n",
    "\n",
    "・DPTの学習\n",
    "　・学習率：1e-4 for decoder\n",
    "\n",
    "・ResNet版\n",
    "　・outputのactivationをreluにしても変化なし1.6e-02くらいが下限でoverfitting\n",
    "\n",
    "・fmap_2025-01-21-20-36-32\n",
    "　・vitl, input normalize, output relu\n",
    "\n",
    "・pre-trained weightをloadできていないことに気づいた => ランダムなencoderを使っていれば，seedの影響は大きいだろう\n",
    "\n",
    "仕切り直し\n",
    "・Transformer_2025-01-21-21-13-05\n",
    "　・悪くない結果（ResNetよりよくなった）\n",
    "・更なる改良案\n",
    "　・depth headとmulti-taskで学習させる（bp signalを増やす）\n",
    "　・encoderをdinov2 weightで初期化する\n",
    "　・encoderもfine-tuneする\n",
    "　・decoder architectureの改良\n",
    "　・data量を増やす\n",
    "・注意点\n",
    "　・過学習気味になっているところから，test lossが大きく減ることがある\n",
    "　・\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
