# -*- coding: utf-8 -*-
"""ae_color_v2.2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xeQp2qkIucHFSXcQHbwMJiyYWB-zUX6K
"""

# from google.colab import drive
# drive.mount('/content/drive', force_remount=False)


# gpu_info = !nvidia-smi
# gpu_info = '\n'.join(gpu_info)
# if gpu_info.find('failed') >= 0:
#   print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
#   print('and then re-execute this cell.')
# else:
#   print(gpu_info)

# from psutil import virtual_memory
# ram_gb = virtual_memory().total / 1e9
# print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

# if ram_gb < 20:
#   print('To enable a high-RAM runtime, select the Runtime > "Change runtime type"')
#   print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')
#   print('re-execute this cell.')
# else:
#   print('You are using a high-RAM runtime!')

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# !rm -rf ./logs/

import os, sys, glob, re, time, datetime
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, losses
from tensorflow.keras.models import Model

from keras.layers import Conv2D, MaxPooling2D, Dense, Input, UpSampling2D, BatchNormalization
#from keras.optimizers import Adam
from keras.optimizers import adam_v2
from keras.callbacks import EarlyStopping, TensorBoard

def numerical_sort(value):
    """
    Splits out any digits in a filename, turns it into an actual number, and returns the result for sorting.
    :param value: filename
    :return:

    author: kei
    date: 20190903
    """
    numbers = re.compile(r'(\d+)')
    parts = numbers.split(value)
    parts[1::2] = map(int, parts[1::2])
    return parts


def explore_ds(path, file_type):
  print(path) #print path
  os.chdir(path)
  ds = sorted(glob.glob(file_type), key=numerical_sort)
  # print(ds) #print contents
  return ds


def visualize_ds(images, vis=False):
  
  samples = len(images)
  # print('total images', samples)

  if vis:
    fig = plt.figure(figsize=(10,samples))
    fig.subplots_adjust(hspace=0.1)
  
  for p in range(samples):
    img = plt.imread(images[p])
    img = cv2.resize(img, (width, height))

    BATCH.append(img) #global variable

    if vis:
      ax = fig.add_subplot(samples//2, 4, p+1)
      ax.axis('off')
      ax.imshow(img)
    

def process_ds(dir_list):
  for group in dir_list:
    images = explore_ds(os.path.join(path, dir, group), '*.jpg')
    visualize_ds(images, vis=False)
    # break



# clone sample images
# path = '/content/drive/MyDrive/ds/pushing'
path = '/home/ryo/Dataset/dataset/pushing'
sys.path.append(path)
dirs = os.listdir(path)

width = 300
height =300 

BATCH = []

start = time.time()
for dir in dirs:
  dir_list = explore_ds(os.path.join(path, dir), 'group*')
  process_ds(dir_list)

  # if dir=='05':
  break
  

end = time.time()
print('total time spent {}'.format((end-start)/60))

print(len(BATCH))

start = time.time()

ds = tf.stack(BATCH) #create tensor of samples

end = time.time()
print('total time spent {}'.format((end-start)/60))

# # split dataset train and test

# ratio = int(len(ds)*.7)

# train_ds = ds[1:ratio,:]
# test_ds = ds[ratio:,:]

# print(train_ds.shape, test_ds.shape)

# # adds the gaussian noise based on the mean and the standard deviation 
# def add_gaussian_noise(data):
#   mean = (10, 10, 10)
#   std = (50, 50, 50)
#   row, col, channel = data.shape
#   noise = np.random.normal(mean, std, (row, col, channel)).astype('uint8')
#   return data + noise
  
# def add_gaussian_to_dataset(data):
#   count = 0
#   end = len(data)
#   output_data = []
#   while count < end:
#     output_data.append(add_gaussian_noise(data[count]))
#     count+=1
#   return np.array(output_data)


# gaussian_train_ds = add_gaussian_to_dataset(train_ds)
# gaussian_test_ds = add_gaussian_to_dataset(test_ds)

# plt.imshow(gaussian_train_ds[1,:])
# print(gaussian_train_ds.shape)

# train_ds = train_ds / 255
# test_ds = test_ds / 255

# # # reduce images
# gaussian_train_ds = gaussian_train_ds / 255.0 
# gaussian_test_ds = gaussian_test_ds / 255.0

# # https://www.tensorflow.org/tutorials/generative/autoencoder
# # put the Activation layer AFTER the BatchNormalization() layer
# tf.compat.v1.reset_default_graph()
# tf.keras.backend.clear_session()


# # initialize the model
# size_=19
# channels_=64
# dense_dim = 500
# dropout = 0.0


## ENCODER ##
def encoder(encoder_input, latent_dim, dense_dim):
  e_conv0 = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(encoder_input)
  pool0 = layers.MaxPooling2D((2, 2), padding='same')(e_conv0)
  batchnorm_0 = layers.BatchNormalization()(pool0)

  e_conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(batchnorm_0)
  pool1 = layers.MaxPooling2D((2, 2), padding='same')(e_conv1)
  batchnorm_1 = layers.BatchNormalization()(pool1)

  e_conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(batchnorm_1)
  pool2 = layers.MaxPooling2D((2, 2), padding='same')(e_conv2)
  batchnorm_2 = layers.BatchNormalization()(pool2)

  e_conv3 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(batchnorm_2)
  pool3 = layers.MaxPooling2D((2, 2), padding='same')(e_conv3)
  batchnorm_3 = layers.BatchNormalization()(pool3)

  flat = layers.Flatten()(batchnorm_3)
  bflat = layers.BatchNormalization()(flat)
  # bflat = layers.Dropout(dropout)(bflat) #

  d1 = layers.Dense(dense_dim, activation='tanh')(bflat)
  d1bn = layers.BatchNormalization()(d1)

  d2 = layers.Dense(latent_dim, activation='tanh')(d1bn)
  encoder_output = layers.BatchNormalization()(d2)

  encoder = keras.Model(encoder_input, encoder_output, name='encoder')
  encoder.summary()
  return encoder


## DECODER ##
def decoder(decoder_input, dense_dim):
  dd1 = layers.Dense(dense_dim, activation='tanh')(decoder_input)
  dd1bn = layers.BatchNormalization()(dd1)

  dd2 = layers.Dense(size_*size_*channels_, activation='tanh')(dd1bn)
  dd2bn = layers.BatchNormalization()(dd2)
  # dd2bn = layers.Dropout(dropout)(dd2bn) #

  reshapedo = layers.Reshape(target_shape=(size_, size_, channels_))(dd2bn)
  d_conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(reshapedo)
  up1 = layers.UpSampling2D((2, 2))(d_conv1)
  dbn1 = layers.BatchNormalization()(up1)

  d_conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(dbn1)
  up2 = layers.UpSampling2D((2, 2))(d_conv2)
  dbn2 = layers.BatchNormalization()(up2)

  d_conv3 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(dbn2)
  up3 = layers.UpSampling2D((2, 2))(d_conv3)
  dbn3 = layers.BatchNormalization()(up3)

  d_conv4 = layers.Conv2D(16, (3, 3), activation='relu')(dbn3)
  up4 = layers.UpSampling2D((2, 2))(d_conv4)
  dbn4 = layers.BatchNormalization()(up4)

  decoder_output = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(dbn4)

  decoder = keras.Model(decoder_input, decoder_output, name='decoder')
  decoder.summary()
  return decoder


def autoencoder(latent_dim=100, dense_dim=500):
  autoencoder_input = keras.Input(shape=(width, height, 3))
  encoded_img = encoder(autoencoder_input, latent_dim, dense_dim)
  decoded_img = decoder(encoded_img, dense_dim)

  autoencoder = keras.Model(autoencoder_input, decoded_img, name='autoencoder')
  return autoencoder


model = autoencoder()
opt = adam_v2.Adam(learning_rate=1e-2) #Adamax
model.compile(loss='mse', metrics=["mae", "acc"], optimizer=opt)
model.summary()

def train():
  start = time.time()

  # create checkpoint and save best weight
  checkpoint_path = "/content/ae_cp/cp.ckpt"
  checkpoint_dir = os.path.dirname(checkpoint_path)

  # Create a callback that saves the model's weights
  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                   save_weights_only=True,
                                                   verbose=1,
                                                   mode='min',
                                                   save_best_only=True)

  # early stopping if not changing for 50 epochs
  early_stop = EarlyStopping(monitor='val_loss',
                             patience=60,
                             verbose=1)

  # reduce learning rate
  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', 
                                                   factor=0.05,
                                                   patience=25, 
                                                   verbose=1,
                                                   min_lr=1e-4)


  # record on tensorboard
  logdir = "logs/ae" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
  tb_callback = keras.callbacks.TensorBoard(log_dir=logdir)

  # train the model
  ae_history = autoencoder.fit(gaussian_train_ds,
                               train_ds, 
                               epochs=500, 
                               batch_size=32,
                               shuffle=True,
                               # validation_split=0.2, # or
                               validation_data=(gaussian_test_ds, test_ds),
                               callbacks=[cp_callback, early_stop, reduce_lr, tb_callback])


  end = time.time()
  print('\ntotal time spent {}'.format((end-start)/60))
  
  plt.figure(1)
  plt.plot(ae_history.epoch, ae_history.history['loss'], label='train_loss')
  plt.plot(ae_history.epoch, ae_history.history['val_loss'], label='test_loss')
  plt.plot(ae_history.epoch, ae_history.history['mae'], label='train_mae')
  plt.plot(ae_history.epoch, ae_history.history['val_mae'], label='val_mae')

  plt.title('Training Loss over the Epochs')
  plt.xlabel('# of Epochs')
  plt.ylabel('Mean Squared Error')
  plt.legend()
  plt.show()

  plt.figure(2)
  plt.plot(ae_history.epoch, ae_history.history['acc'], label='train_acc')
  plt.plot(ae_history.epoch, ae_history.history['val_acc'], label='val_acc')

  plt.title('Accuracy over the epochs')
  plt.xlabel('# of Epochs')
  plt.ylabel('Accuracy')
  plt.legend()
  plt.show()


def test():
  # # load_best_checkpoint and evaluate
  # cp_model = autoencoder(latent_dim)
  # cp_model.compile(loss='mse', optimizer=opt)
  autoencoder.load_weights(checkpoint_path)
  cp_loss = autoencoder.evaluate(gaussian_test_ds, test_ds)

  # # evaluate the model on the test set
  # final_loss = autoencoder.evaluate(gaussian_test_ds, test_ds)

  """# DENOISED IMAGES"""

  # run model on the test_ds to reconstruct
  cp_result = autoencoder.predict(gaussian_test_ds)

  n = 10
  idx = [np.random.randint(1,100) for i in range(n)]
  plt.figure(figsize=(20, 4))
  for i in range(n):

    # display original + noise
    ax = plt.subplot(2, n, i + 1)
    plt.title("original + noise")
    # plt.imshow((gaussian_test_ds[idx[i]]*255).astype(np.uint8))
    plt.imshow(test_ds[idx[i]])
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    bx = plt.subplot(2, n, i + n + 1)
    plt.title("reconstructed")
    plt.imshow((cp_result[idx[i]]*255).astype(np.uint8))
    bx.get_xaxis().set_visible(False)
    bx.get_yaxis().set_visible(False)
  plt.show()

  final_result = autoencoder.predict(gaussian_test_ds)

  samples = len(final_result)
  fig = plt.figure(figsize=(15, samples))
  for p in range(1, samples):
    ax = fig.add_subplot(samples//2, 5, p+1)
    ax.imshow((final_result[p]*255).astype(np.uint8))
    ax.axis('off')

    """# Original Test Images"""

  fig = plt.figure(figsize=(15, samples))
  for p in range(1, samples):
    ax = fig.add_subplot(samples//2, 5, p+1)
    ax.imshow(test_ds[p])
    ax.axis('off')

# https://www.tensorflow.org/tensorboard/scalars_and_keras
# %tensorboard --logdir logs/ae
