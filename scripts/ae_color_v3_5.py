# -*- coding: utf-8 -*-
"""ae_color_v3.3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11eBSz3FHYxRLxHblDhWT_UjLJtItlY7b
"""


import os, sys, glob, re, time
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, losses
from tensorflow.keras.models import Model

from keras.layers import Conv2D, MaxPooling2D, Dense, Input, UpSampling2D, BatchNormalization
from keras.callbacks import EarlyStopping, TensorBoard
from keras.layers import GaussianNoise
from PIL import Image


def numerical_sort(value):
    """
    Splits out any digits in a filename, turns it into an actual number, and returns the result for sorting.
    :param value: filename
    :return:

    author: kei
    date: 20190903
    """
    numbers = re.compile(r'(\d+)')
    parts = numbers.split(value)
    parts[1::2] = map(int, parts[1::2])
    return parts


def visualize_ds(images, max_samples=20):
    samples = min(len(images), max_samples)

    fig = plt.figure(figsize=(10,samples))
    fig.subplots_adjust(hspace=0.1)
  
    for p in range(samples):
        ax = fig.add_subplot(samples//4, 4, p+1)
        ax.axis('off')
        ax.imshow(images[p])

def generate_mask(path):
    mask_img_path = path.replace(".jpg", "_layer.png")
    mask_img = cv2.imread(mask_img_path)
    robot_mask = np.logical_and.reduce(mask_img == np.array([255,255,255]), axis=2)
    object_mask = np.logical_and.reduce(mask_img == np.array([255,0,0]), axis=2) # BGR
    foreground_mask = np.bitwise_or(robot_mask, object_mask)
    background_mask = np.bitwise_not(foreground_mask)
    fg_weight = 1.0
    bg_weight = 0.4
    mask_img = np.zeros(mask_img.shape, dtype=np.float32)
    mask_img[foreground_mask] = np.array([fg_weight, fg_weight, fg_weight])
    mask_img[background_mask] = np.array([bg_weight, bg_weight, bg_weight])
    mask_img = cv2.resize(mask_img, dsize=(height, width))
    return mask_img

def process_ds(paths, use_mask=True, vis=False):
    print('total images', paths)
    for p in paths:
        img = plt.imread(p)
        img = cv2.resize(img, (height, width))
        BATCH.append(img) #global variable

        if use_mask:
            WEIGHT_BATCH.append(generate_mask(p))

    if vis:
        visualize_ds(BATCH)
    if vis and use_mask:
            visualize_ds(WEIGHT_BATCH)

# def create_mask(segmentation_img, object_weight, background_weight):
#     ''' didn't work '''
#     weight = np.where((segmentation_img == 29.0) | (segmentation_img == 255.0) |
#                       (segmentation_img == 215.0) | (segmentation_img == 223.0) |
#                       (segmentation_img == 201.0), object_weight, background_weight).astype(np.float32)
#     return weight


path = '/home/ryo/Dataset/dataset'
sys.path.append(path)
dirs = ['pushing']

height = 160
width = 80
BATCH = []
WEIGHT_BATCH = []

def load_dataset(visualize=False):
    start = time.time()
    for dir in dirs:
        images = sorted(glob.glob(os.path.join(path, dir, 'group*', 'image_frame*.jpg'), recursive=True), key=numerical_sort)

        images = images[::5]
        process_ds(images, vis=visualize)

    end = time.time()
    print('total time spent {}'.format((end-start)/60))


load_dataset()
print(len(BATCH))

start = time.time()

ds = tf.stack(BATCH) #create tensor of samples

end = time.time()
print('total time spent {}'.format((end-start)/60))

ratio = int(len(ds)*.7)

train_ds = ds[1:ratio,:]
test_ds = ds[ratio:,:]

train_weights = tf.stack(WEIGHT_BATCH[1:ratio])
test_weights = tf.stack(WEIGHT_BATCH[ratio:])

print(train_ds.shape, test_ds.shape)


def add_gaussian_to_dataset(data):
    return data + np.random.normal(scale=0.0, size=data.shape)

train_ds = train_ds / 255
test_ds = test_ds / 255
gaussian_train_ds = train_ds
gaussian_test_ds = test_ds

# gaussian_train_ds = add_gaussian_to_dataset(train_ds)
# gaussian_test_ds = add_gaussian_to_dataset(test_ds)

#plt.imshow((gaussian_train_ds[1,:]*255).astype(np.uint8))

# https://www.tensorflow.org/tutorials/generative/autoencoder
# put the Activation layer AFTER the BatchNormalization() layer

loss_tracker = keras.metrics.Mean(name="loss")
val_loss_tracker = keras.metrics.Mean(name="val_loss")

class Autoencoder(tf.keras.Model):

    def __init__(self, dense_dim, latent_dim):
        super(Autoencoder, self).__init__()
        self.dense_dim = dense_dim
        self.latent_dim = latent_dim
  
        self.encoder = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=(width, height, 3)),

            GaussianNoise(0.2),

            tf.keras.layers.Conv2D(8, kernel_size=3, strides=1, padding='same', activation='selu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPool2D(pool_size=2),
          
            tf.keras.layers.Conv2D(16, kernel_size=3, strides=1, padding='same', activation='selu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPool2D(pool_size=2),

            tf.keras.layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='selu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPool2D(pool_size=2),
          
            tf.keras.layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='selu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.MaxPool2D(pool_size=2),

            tf.keras.layers.Flatten(),

            tf.keras.layers.Dense(self.latent_dim, activation='selu'),
            
        ])
  
        self.decoder = tf.keras.Sequential([
            tf.keras.layers.InputLayer(input_shape=(self.latent_dim,)),
            
            tf.keras.layers.Dense(5*10*channels_, activation='selu'),
            tf.keras.layers.BatchNormalization(),

            tf.keras.layers.Reshape(target_shape=(5, 10, channels_)),
            tf.keras.layers.BatchNormalization(),

            tf.keras.layers.Conv2DTranspose(64, kernel_size=3, strides=1, padding='same', activation='selu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.UpSampling2D(),

            tf.keras.layers.Conv2DTranspose(32, kernel_size=3, strides=1, padding='same', activation='selu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.UpSampling2D(),
          
            tf.keras.layers.Conv2DTranspose(16, kernel_size=3, strides=1, padding='same', activation='selu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.UpSampling2D(),
          
            tf.keras.layers.Conv2DTranspose(8, kernel_size=3, strides=1, padding='same', activation='selu'),
            tf.keras.layers.BatchNormalization(),
            tf.keras.layers.UpSampling2D(),
          
            tf.keras.layers.Conv2DTranspose(3, kernel_size=3, strides=1, padding='same', activation='sigmoid'),

        ])

    def call(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

    def weighted_loss(self, y, y_pred, weight):
        wy = tf.cast(y, tf.float32) * weight
        wy_pred = y_pred * weight
        loss = keras.losses.mean_squared_error(wy, wy_pred)
        return loss
    
    def train_step(self, data):
        (x, weight), y = data

        with tf.GradientTape() as tape:
            y_pred = self(x, training=True) # Forward pass
            loss = self.weighted_loss(y, y_pred, weight) # Compute our own loss
            #loss = keras.losses.mean_squared_error(y, y_pred)

        trainable_vars = self.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        # Compute our own metrics
        loss_tracker.update_state(loss)
        return {"loss": loss_tracker.result()}

    def test_step(self, data):
        (x, weight), y = data
        
        y_pred = self(x, training=False) # Forward pass

        val_loss = self.weighted_loss(y, y_pred, weight)
        val_loss_tracker.update_state(val_loss)
        return {"loss": val_loss_tracker.result()}

    @property
    def metrics(self):
        return [loss_tracker, val_loss_tracker]
        


# initialize the model
dense_dim = 512
latent_dim = 128
channels_ = 64
dropout = 0.25

opt = keras.optimizers.Adamax(learning_rate=0.001)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    gaussian_auto_encoder = Autoencoder(dense_dim, latent_dim)
    gaussian_auto_encoder.compile(optimizer=opt)

# create checkpoint and save best weight
checkpoint_path = "/home/ryo/Program/Ashesh_colab/ae_cp/cp.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)


def train():

    # see model summary
    gaussian_auto_encoder.encoder.summary()
    gaussian_auto_encoder.decoder.summary()

    start = time.time()

    # Create a callback that saves the model's weights
    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                     save_weights_only=True,
                                                     verbose=1,
                                                     mode='min',
                                                     save_best_only=True)

    # early stopping if not changing for 50 epochs
    early_stop = EarlyStopping(monitor='val_loss',
                               patience=100)

    # reduce learning rate
    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', 
                                                     factor=0.1,
                                                     patience=50, 
                                                     verbose=1,
                                                     min_lr=0.00001)

    # train the model
    gaussian_history = gaussian_auto_encoder.fit((gaussian_train_ds, train_weights),
                                                 train_ds, 
                                                 epochs=500,
                                                 batch_size=64,
                                                 shuffle=True,
                                                 validation_data=((gaussian_test_ds, test_weights), test_ds),
                                                 callbacks=[cp_callback, early_stop, reduce_lr])

    end = time.time()
    print('\ntotal time spent {}'.format((end-start)/60))

    plt.plot(gaussian_history.epoch, gaussian_history.history['loss'], label='train_loss')
    plt.plot(gaussian_history.epoch, gaussian_history.history['val_loss'], label='test_loss')
    plt.title('Epochs on Training Loss')
    plt.xlabel('# of Epochs')
    plt.ylabel('Mean Squared Error')
    plt.legend()
    plt.show()
    return gaussian_history


def test():
    # load_best_checkpoint and evaluate
    cp_model = Autoencoder(dense_dim, latent_dim)
    cp_model.compile(loss='mse', optimizer=opt)
    cp_model.load_weights(checkpoint_path)

    # cp_loss = cp_model.evaluate(gaussian_test_ds, test_ds)
    # evaluate the model on the test set
    # final_loss = gaussian_auto_encoder.evaluate(gaussian_test_ds, test_ds)

    """# DENOISED IMAGES"""

    # run model on the test_ds to reconstruct
    cp_result = cp_model.predict((gaussian_test_ds, test_weights))
    
    n = 10
    #idx = [np.random.randint(1,20) for i in range(n)]
    idx = [np.random.randint(1,20) for i in range(n)]
    plt.figure(figsize=(20, 4))
    for i in range(n):
        # display original
        ax = plt.subplot(3, n, i + 1)
        plt.title("original")
        plt.imshow(test_ds[idx[i]])
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

        # display reconstruction
        cx = plt.subplot(3, n, i + n + 1)
        plt.title("reconstructed")
        plt.imshow(cp_result[idx[i]])
        cx.get_xaxis().set_visible(False)
        cx.get_yaxis().set_visible(False)

    plt.show()

    # final_result = gaussian_auto_encoder.predict(gaussian_test_ds)

    # samples = len(final_result)
    # fig = plt.figure(figsize=(15, samples))
    # for p in range(1, samples):
    #     ax = fig.add_subplot(samples//2, 5, p+1)
    #     ax.imshow((final_result[p]*255).astype(np.uint8))
    #     ax.axis('off')

    # """# Original Test Images"""
    
    # fig = plt.figure(figsize=(15, samples))
    # for p in range(1, samples):
    #     ax = fig.add_subplot(samples//2, 5, p+1)
    #     ax.imshow(test_ds[p])
    #     ax.axis('off')
